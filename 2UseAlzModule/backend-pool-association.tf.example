# ============================================================================
# EXAMPLE: Adding VMs to Load Balancer Backend Pool
# ============================================================================
# This file shows how to associate existing VM NICs with the load balancer
# backend pool after the load balancer has been deployed.
#
# Add this to your Terraform configuration AFTER deploying the load balancer.
# ============================================================================

# ----------------------------------------------------------------------------
# OPTION A: Associate Existing VM NICs with Backend Pool
# ----------------------------------------------------------------------------
# Use this when you already have VMs deployed and want to add them to the LB

# Example: Add VM1's NIC to the backend pool
resource "azurerm_network_interface_backend_address_pool_association" "vm1" {
  network_interface_id    = "/subscriptions/6e05c1d3-15e2-4383-a0dc-2d5a20e44289/resourceGroups/Skynet-VMs-RG/providers/Microsoft.Network/networkInterfaces/Skynet01-nic"
  ip_configuration_name   = "internal"  # Must match the IP config name on the NIC
  backend_address_pool_id = module.internal_lb.backend_address_pool_id
}

# Example: Add VM2's NIC to the backend pool
resource "azurerm_network_interface_backend_address_pool_association" "vm2" {
  network_interface_id    = "/subscriptions/6e05c1d3-15e2-4383-a0dc-2d5a20e44289/resourceGroups/Skynet-VMs-RG/providers/Microsoft.Network/networkInterfaces/Skynet02-nic"
  ip_configuration_name   = "internal"
  backend_address_pool_id = module.internal_lb.backend_address_pool_id
}

# ----------------------------------------------------------------------------
# OPTION B: Create New VMs with Backend Pool Association
# ----------------------------------------------------------------------------
# Use this when creating new VMs that should be in the backend pool from the start

# Data source to get existing subnet
data "azurerm_subnet" "vm_subnet" {
  name                 = "subnet2"
  resource_group_name  = "m-spokeconfig-rg"
  virtual_network_name = "SDSvNetTest-vnet"
}

# Create Network Interface with Backend Pool Association
resource "azurerm_network_interface" "web_vm1_nic" {
  name                = "web-vm1-nic"
  location            = "uksouth"
  resource_group_name = "rg-lb-prod"

  ip_configuration {
    name                          = "internal"
    subnet_id                     = data.azurerm_subnet.vm_subnet.id
    private_ip_address_allocation = "Dynamic"
  }

  tags = {
    environment = "prod"
  }
}

# Associate the NIC with the backend pool
resource "azurerm_network_interface_backend_address_pool_association" "web_vm1" {
  network_interface_id    = azurerm_network_interface.web_vm1_nic.id
  ip_configuration_name   = "internal"
  backend_address_pool_id = module.internal_lb.backend_address_pool_id
}

# Create the Virtual Machine
resource "azurerm_windows_virtual_machine" "web_vm1" {
  name                = "web-vm1"
  location            = "uksouth"
  resource_group_name = "rg-lb-prod"
  size                = "Standard_B2s"
  admin_username      = "azureuser"
  admin_password      = var.admin_password  # Set in tfvars or as sensitive variable

  network_interface_ids = [
    azurerm_network_interface.web_vm1_nic.id
  ]

  os_disk {
    name                 = "web-vm1-osdisk"
    caching              = "ReadWrite"
    storage_account_type = "StandardSSD_LRS"
  }

  source_image_reference {
    publisher = "MicrosoftWindowsServer"
    offer     = "WindowsServer"
    sku       = "2022-Datacenter"
    version   = "latest"
  }

  tags = {
    environment = "prod"
    role        = "webserver"
  }
}

# ----------------------------------------------------------------------------
# OPTION C: Using Data Sources to Reference Existing Resources
# ----------------------------------------------------------------------------
# Use this when VMs are managed elsewhere but you want to add them to your LB

# Look up existing VM NIC
data "azurerm_network_interface" "existing_vm_nic" {
  name                = "existing-vm-nic"
  resource_group_name = "rg-vms"
}

# Add the existing NIC to the backend pool
resource "azurerm_network_interface_backend_address_pool_association" "existing_vm" {
  network_interface_id    = data.azurerm_network_interface.existing_vm_nic.id
  ip_configuration_name   = "ipconfig1"  # Check the actual name in Azure Portal
  backend_address_pool_id = module.internal_lb.backend_address_pool_id
}

# ----------------------------------------------------------------------------
# OPTION D: Loop Through Multiple VMs (Advanced)
# ----------------------------------------------------------------------------
# Use this when you have many VMs with a consistent naming pattern

variable "vm_names" {
  description = "List of VM names to add to backend pool"
  type        = list(string)
  default     = ["web-vm-01", "web-vm-02", "web-vm-03"]
}

# Look up each VM's NIC
data "azurerm_network_interface" "vm_nics" {
  for_each            = toset(var.vm_names)
  name                = "${each.value}-nic"
  resource_group_name = "rg-vms"
}

# Add all NICs to the backend pool
resource "azurerm_network_interface_backend_address_pool_association" "vms" {
  for_each                = data.azurerm_network_interface.vm_nics
  network_interface_id    = each.value.id
  ip_configuration_name   = "internal"
  backend_address_pool_id = module.internal_lb.backend_address_pool_id
}

# ============================================================================
# HOW TO USE THIS FILE
# ============================================================================
#
# 1. Choose the option that fits your scenario:
#    - Option A: You have VMs, know their NIC resource IDs
#    - Option B: You're creating new VMs with Terraform
#    - Option C: VMs exist but managed elsewhere
#    - Option D: Many VMs with consistent naming
#
# 2. Copy the relevant section to your main.tf or a separate file like backend-vms.tf
#
# 3. Update the resource IDs, names, and IP configuration names to match your VMs
#
# 4. Run terraform plan to verify the associations
#
# 5. Run terraform apply to add VMs to the backend pool
#
# ============================================================================
# FINDING YOUR NIC INFORMATION
# ============================================================================
#
# To find NIC Resource IDs:
#   az network nic show --name <nic-name> --resource-group <rg-name> --query id -o tsv
#
# To find IP Configuration Name on a NIC:
#   az network nic show --name <nic-name> --resource-group <rg-name> --query "ipConfigurations[0].name" -o tsv
#
# Example for Skynet VMs:
#   az network nic show --name Skynet01-nic --resource-group Skynet-VMs-RG --query id -o tsv
#   az network nic show --name Skynet01-nic --resource-group Skynet-VMs-RG --query "ipConfigurations[0].name" -o tsv
#
# ============================================================================
# VERIFICATION AFTER DEPLOYMENT
# ============================================================================
#
# 1. Check backend pool members in Azure Portal:
#    Load Balancer → Backend pools → Click your pool → View members
#
# 2. Or use Azure CLI:
#    az network lb address-pool show \
#      --resource-group rg-lb-prod \
#      --lb-name sdstest-ilb-01-prod \
#      --name backend-pool \
#      --query backendIPConfigurations[].id
#
# 3. Verify health probe status:
#    Load Balancer → Metrics → Backend Health
#
# ============================================================================
